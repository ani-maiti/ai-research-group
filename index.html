<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Maiti Research Group - AI, Deep Learning, NLP">
    <title>AI Research Group</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header>
        <div class="container">
			<h1>Aniruddha Maiti</h1>
            <h2>AI Research Group</h2>
            <h2>West Virginia State University</h2>
            <p> Artificial Intelligence (AI) | Agents | Deep Learning | NLP</p>
        </div>
    </header>

    <!-- Navigation bar -->
    <nav>
        <ul class="navbar">
            <li><a href="index.html" class="active">Home</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="people.html">People</a></li>
            <li><a href="teaching.html">Teaching</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>

    <!-- Research Group Section -->
    <section class="container">
        <h2>Welcome to the AI Research Group</h2>
        <p>Our research focuses on Artificial Intelligence, Deep Learning, Natural Language Processing, and Data Science, with applications in healthcare, scientific discovery, and autonomous systems. We are also interested in exploring agentic AI systems, which have the capability to learn, adapt, and make autonomous decisions. Our goal is to develop innovative, scalable, and interpretable AI solutions that address real-world challenges while advancing the theoretical foundations of machine learning.</p>


        <!-- Spacer -->
	<div style="height: 20px;"></div>


	<div class="profile-pic">
	    <img src="images/dr_maiti_serious.jpg" alt="Dr. Aniruddha Maiti" class="profile-img serious">
	    <img src="images/dr_maiti_fun.jpg" alt="Dr. Aniruddha Maiti Fun" class="profile-img fun">
	</div>

        
        
         <!-- Spacer -->
	<div style="height: 30px;"></div>
        
        
        
        <h3>Principal Investigator</h3>
        <p><strong>Dr. Aniruddha Maiti</strong>  
        Assistant Professor, West Virginia State University  
        Verified Email: <a href="mailto:wvstateu.edu" style="color:#8bc34a;">wvstateu.edu</a></p>

        <h3>Research Areas</h3>
        <ul>
            <li>Deep Learning & NLP</li>
            <li>Knowledge Distillation</li>
            <li>AI in Medical Applications</li>
            <li>Data Science & Multi-Modal Learning</li>
        </ul>
    </section>

    <!-- Current Research Projects -->
    <section class="container research-section">
        <h2>Current Research Projects</h2>
        
	<div class="research-item">
	    <h3>Knowledge Distillation</h3>
	    <p><strong>Student: Samuel Adewumi (IBM Masters Fellow)</strong></p>
	    
	    <!-- Image Section (Placeholder for now) -->
	    <div class="research-images">
		<img src="images/samuel_project1.jpg" alt="Project Visualization 1" class="research-img">
		<img src="images/samuel_project2.jpg" alt="Project Visualization 2" class="research-img">
	    </div>
	    
	    <p>This project explores various loss functions (token-level, feature-level, and patch-level) for training student models using PyTorch.  
	    The study focuses on knowledge transfer from a teacher Vision Transformer (ViT-Small) to student models with 2-10 million parameters.</p>
	    
	</div>
	
	<div class="research-item">
	    <h3>Minimal Fine-Tuning for Multi-Modal Deep Learning</h3>
	    <p><strong>Student: Renata Castellanos</strong></p>
	    <p><strong>Supported by: NASA Space Grant Research Enhancement Award</strong></p>

	    <!-- Image Section (Placeholder for now) -->
	    <div class="research-images">
		<img src="images/renata_project1.jpg" alt="Point Cloud Data Processing" class="research-img">
		<img src="images/renata_project2.jpg" alt="Multi-Modal Fusion Visualization" class="research-img">
	    </div>

	    <p>This project focuses on building a low-resource pipeline for fine-tuning pretrained deep learning models on point cloud and image data using limited GPU resources.  
	    The aim is to make AI research more accessible for undergraduate students by enabling multi-modal learning on personal laptops.</p>

	</div>
	
        <div class="research-item">
            <h3> Evaluating Structured Intermediate Representations (JSON) in NLP</h3>
            <p><strong>Collaboration: Dr. Sridhar Acharya Malkaram  Students: Temesgen Alema Tikure & Zichun Wang</strong></p>
            <p>This study investigates how structured representations impact text-to-vector transformations using 7B -13B Language Models.</p>
        </div>


    </section>
    
    <!-- News Section -->
<section class="container news-section">
    <h2>ðŸ“¢ News & Announcements</h2>
    <ul>


        <li>
            <strong>[April 2025]</strong> ðŸŽ‰ <strong> We received EPSCoR Seed Grant : For our research on AI-Driven Agents for Sequential Code Execution </strong>
        </li>


        <li>
            <strong>[March 2025]</strong> ðŸŽ‰ <strong>Congratulations!! Temesgen Alema Tikure, Zichun Wang, Samuel Adewumi !!! </strong>  
            Our paper <strong>"Comparative Analysis of OpenAI GPT-4o and DeepSeek R1 for Scientific Text Categorization Using Prompt Engineering"</strong> has been  
            <strong>accepted</strong> for the <strong>2025 ASEE North Central Section (NCS) Annual Conference</strong>!  
            <p>
                This study explores how <strong>large language models</strong> (GPT-4o and DeepSeek R1) categorize sentences from scientific papers using <strong>prompt engineering</strong>.  
                It introduces a <strong>new evaluation method</strong> and a dataset compiled from diverse scientific domains to compare their effectiveness and consistency in text categorization.
            </p>
        </li>

        <li>
            <strong>[January 2025]</strong> ðŸŽ‰ <strong>Congratulations!</strong>  
            Our paper <strong>"SaViD: Spectravista Aesthetic Vision Integration for Robust and Discerning 3D Object Detection in Challenging Environments"</strong> has been  
            <strong>accepted</strong> at <strong>ICRA 2025</strong>, the premier conference in Robotics and AI!
            <p>
                This research presents <strong>SaViD</strong>, a novel <strong>three-stage fusion alignment framework</strong> designed to tackle <strong>long-range 3D object detection challenges</strong> in autonomous driving.
            </p>
        </li>
        
        <li>
            <strong>[January 2025]</strong> ðŸŽ‰ <strong> Our Graduate Student Samuel Adewumi got 2024 IBM MASTERS Fellowship Award. Congratullations Samuel !!!</strong>
        </li>

        <li>
            <strong>[October 2024]</strong> ðŸŽ‰ <strong> We received NASA Space Grant Research Enhancement Award, 2024 by NASA West Virginia Space Grant Consortium :  </strong>  
           project <strong>"Minimal Fine Tuning of Multi-Modal Deep Learning Task Using Point Cloud and Image Data in Low GPU Resource Environment. "</strong> 

        </li>

        <li>
            <strong>[July 2024]</strong> ðŸŽ‰ Our paper - <strong> Contextual Vision Transformers (Q-ICVT) </strong> - has been <strong>accepted at CIKM 2024!</strong>
        </li>

    </ul>
	</section>




    <!-- Footer -->
    <footer>
        <div class="container">
            <p>&copy; 2024 AI Research Group. All Rights Reserved.</p>
        </div>
    </footer>

</body>
</html>
